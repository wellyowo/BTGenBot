{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging huggingface for auth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check requirements\n",
    "# !pip3 install -q -r requirements.txt\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "notebook_directory = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "directory = os.path.join(notebook_directory, \"generation_result\")\n",
    "if not os.path.exists(directory):\n",
    "\tos.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed library and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -r requirements.txt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch, accelerate\n",
    "\n",
    "# Models path\n",
    "codellama_model = 'codellama/CodeLlama-7b-Instruct-hf'\n",
    "\n",
    "# Adapters path\n",
    "codellama_adapter = 'AIRLab-POLIMI/codellama-7b-instruct-hf-btgenbot-adapter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_behavior_tree(result):\n",
    "    # Define regular expression pattern to extract the behavior tree from the complete output\n",
    "    pattern = r'<root .*?</root>'\n",
    "    matches = re.findall(pattern, result, re.DOTALL)\n",
    "\n",
    "    if matches:\n",
    "        final_tree = matches[-1]\n",
    "        return final_tree\n",
    "    else:\n",
    "        print(\"No start root of behavior tree please check the output\")\n",
    "    return None \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained codellama_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a258afe8509b4a1485d47e6f441d4375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select here the model and the corresponding adapter\n",
    "cache_dir = '/home/arg/BTGenBot/model'\n",
    "model_id = codellama_model\n",
    "adapter_id = codellama_adapter\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path = model_id,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path = model_id,\n",
    "    quantization_config = quantization_config,\n",
    "    torch_dtype = torch.float16,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Task description, similar example task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample task of paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"<<SYS>> You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.\\n <</SYS>>\"\n",
    "task = \"\"\"The behavior tree first checks if there is any object in view. If there is an object, it simultaneously executes control actions for linear x and linear y directions. If no object is in view, the robot will then proceed to explore a pattern block.\"\"\"\n",
    "\n",
    "# One-shot example\n",
    "example_task = \"\"\"The behavior tree represents a robot's navigation system with arm activity. The robot must visit the location \"Station A\", then follow the aruco with ID=7. The only available actions that must be used in the behavior tree are: \"MoveTo\", \"FollowAruco\".\"\"\"\n",
    "example_output = \"\"\"\n",
    "<root main_tree_to_execute = \"MainTree\" >\n",
    "    <BehaviorTree ID=\"MainTree\">\n",
    "        <Sequence>\n",
    "            <MoveTo location=\"Station A\"/>\n",
    "            <FollowAruco id=\"7\"/>\n",
    "        </Sequence>\n",
    "    </BehaviorTree>\n",
    "</root>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for locobot navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"<<SYS>> You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.\\n <</SYS>>\"\n",
    "task = \"\"\"The behavior tree represents a robot's navigation between different workspace for checking the area. \n",
    "The order of action is the following. \n",
    "Start from \"start_position\" and move to \"workstation_A\", then \"workstation_B\" and finally \"workstation_C\". After go through all workspace move back to \"start_position\", for security if the robot see the red light it need to \"stop\" immediately. \n",
    "The only available actions that must be used in the behavior tree are: \"MoveTo\", \"Pick\", \"Press\", \"Drop\", \"Red_light_in_view\", \"stop\".\"\"\"\n",
    "\n",
    "example_task = \"\"\"The behavior tree represents a robot's navigation between different workspace for checking the area. \n",
    "The order of action is the following. \n",
    "Start from \"start_position\" and move to \"workstation_A\", then \"workstation_B\" and finally \"workstation_C\". After go through all workspace move back to \"start_position\", for checking the area is clear, if the robot see the red ball, it need to \"pick\" the red ball up.\n",
    "The only available actions that must be used in the behavior tree are: \"MoveTo\", \"Pick\", \"Press\", \"Drop\",\"Red_ball_in_view\".\"\"\"\n",
    "example_output = \"\"\"\n",
    "<root main_tree_to_execute = \"MainTree\" >\n",
    "    <BehaviorTree ID=\"MainTree\">\n",
    "        <fallback>\n",
    "            <Sequence>\n",
    "                <Red_ball_in_view/>\n",
    "                <Pick item=\"Red_ball\"/>\n",
    "            <Sequence>   \n",
    "            <Sequence>\n",
    "                <MoveTo location=\"start_position\"/>\n",
    "                <MoveTo location=\"workstattion_A\"/>\n",
    "                <MoveTo location=\"workstattion_B\"/>\n",
    "                <MoveTo location=\"workstattion_C\"/>\n",
    "                <MoveTo location=\"start_position\"/>\n",
    "            </Sequence>\n",
    "        </fallback>\n",
    "        \n",
    "    </BehaviorTree>\n",
    "</root>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of pretrain base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = context + \"[INST]\" + task + \"[/INST]\"\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<SYS>> You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.\n",
      " <</SYS>>[INST]The behavior tree first checks if there is any object in view. If there is an object, it simultaneously executes control actions for linear x and linear y directions. If no object is in view, the robot will then proceed to explore a pattern block.[/INST]\n"
     ]
    }
   ],
   "source": [
    "print(eval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    result = tokenizer.decode(base_model.generate(**model_input, max_new_tokens=3000)[0], skip_special_tokens=True)\n",
    "    print(\"Generation result of base model\")\n",
    "    print(result)\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    xml_tree_base  = extract_behavior_tree(result)\n",
    "    print(xml_tree_base)\n",
    "    print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_base = os.path.join(directory, \"response_base.txt\")\n",
    "with open(response_base, \"w+\") as file:\n",
    "    file.write(result)\n",
    "    \n",
    "xml_base_filename = os.path.join(directory, \"response_base_xml_tree.txt\")\n",
    "with open(xml_base_filename, \"w+\") as file:\n",
    "    file.write(xml_tree_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26573a9932142698d89af8314ba81e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b680aefc5566457d9014e579bb3fe882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/80.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:83: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_id)\n",
    "finetuned_model = finetuned_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation result of finetune model\n",
      "<<SYS>> You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.\n",
      " <</SYS>>[INST]The behavior tree first checks if there is any object in view. If there is an object, it simultaneously executes control actions for linear x and linear y directions. If no object is in view, the robot will then proceed to explore a pattern block.[/INST] <root main_tree_to_execute=\"BehaviorTree\">\n",
      "    <BehaviorTree ID=\"BehaviorTree\">\n",
      "        <Sequence>\n",
      "            <Fallback>\n",
      "                <Sequence>\n",
      "                    <Condition ID=\"HasObjectInView\"/>\n",
      "                    <Sequence>\n",
      "                        <Action ID=\"RobotControlAction\" linear_x=\"1\" linear_y=\"1\"/>\n",
      "                    </Sequence>\n",
      "                </Sequence>\n",
      "            </Fallback>\n",
      "            <Action ID=\"RobotExploreBlock\" pattern_block=\"1\"/>\n",
      "        </Sequence>\n",
      "    </BehaviorTree>\n",
      "</root>\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "<root main_tree_to_execute=\"BehaviorTree\">\n",
      "    <BehaviorTree ID=\"BehaviorTree\">\n",
      "        <Sequence>\n",
      "            <Fallback>\n",
      "                <Sequence>\n",
      "                    <Condition ID=\"HasObjectInView\"/>\n",
      "                    <Sequence>\n",
      "                        <Action ID=\"RobotControlAction\" linear_x=\"1\" linear_y=\"1\"/>\n",
      "                    </Sequence>\n",
      "                </Sequence>\n",
      "            </Fallback>\n",
      "            <Action ID=\"RobotExploreBlock\" pattern_block=\"1\"/>\n",
      "        </Sequence>\n",
      "    </BehaviorTree>\n",
      "</root>\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "finetuned_model.eval()\n",
    "with torch.no_grad():\n",
    "    fine_tune_result = tokenizer.decode(finetuned_model.generate(**model_input, max_new_tokens=3000)[0], skip_special_tokens=True)\n",
    "    print(\"Generation result of finetune model\")\n",
    "    print(fine_tune_result)\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    xml_tree_finetune = extract_behavior_tree(fine_tune_result)\n",
    "    print(xml_tree_finetune)\n",
    "    print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_finetune = os.path.join(directory, \"response_finetune.txt\")\n",
    "with open(response_finetune, \"w+\") as file:\n",
    "    file.write(fine_tune_result)\n",
    "    \n",
    "xml_fintune_filename = os.path.join(directory, \"response_finetune_xml_tree.txt\")\n",
    "with open(xml_fintune_filename, \"w+\") as file:\n",
    "    file.write(xml_tree_finetune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn XML behavior tree to CMU symbolic tree version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
